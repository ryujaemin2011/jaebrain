import subprocess
import time
import signal
import sys
import os
import csv
import numpy as np
import pandas as pd
from collections import deque
from pylsl import StreamInlet, resolve_byprop
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras import layers, models

# --------------------------------------------
# âš™ï¸ ì„¤ì •
DATA_FOLDER = "eeg_data"
MODEL_PATH = "eeg_thought_model.h5"
WINDOW_SIZE = 128
STRIDE = 64
COLS = ['TP9', 'AF7', 'AF8', 'TP10']
DURATION = 30  # ìˆ˜ì§‘ ì‹œê°„ (ì´ˆ)


# --------------------------------------------


# --------------------------------------------
# 1. muselsl stream ì‹¤í–‰
def start_stream():
    print("ğŸ§  muselsl stream ì‹œì‘ ì¤‘...")
    process = subprocess.Popen(["muselsl", "stream"])
    time.sleep(5)
    return process


def stop_stream(process):
    print("ğŸ›‘ muselsl stream ì¢…ë£Œ ì¤‘...")
    process.terminate()


# --------------------------------------------


# --------------------------------------------
# 2. EEG ë°ì´í„° ìˆ˜ì§‘
def collect_data(label):
    os.makedirs(DATA_FOLDER, exist_ok=True)
    filename = os.path.join(DATA_FOLDER, f"{label}_{int(time.time())}.csv")

    print("ğŸ” EEG ìŠ¤íŠ¸ë¦¼ íƒìƒ‰ ì¤‘...")
    streams = resolve_byprop('type', 'EEG', timeout=10)
    if not streams:
        raise RuntimeError("âŒ EEG ìŠ¤íŠ¸ë¦¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    inlet = StreamInlet(streams[0])
    print(f"âœ… EEG ìŠ¤íŠ¸ë¦¼ ì—°ê²°ë¨. {label} ë¼ë²¨ ë°ì´í„° {DURATION}ì´ˆ ë™ì•ˆ ìˆ˜ì§‘ ì¤‘...")

    with open(filename, 'w', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(COLS + ['timestamp', 'label'])
        start_time = time.time()
        while time.time() - start_time < DURATION:
            sample, timestamp = inlet.pull_sample()
            writer.writerow(sample + [timestamp, label])

    print(f"âœ… ì €ì¥ ì™„ë£Œ: {filename}")


# --------------------------------------------


# --------------------------------------------
# 3. ë°ì´í„° ì „ì²˜ë¦¬ (ìœˆë„ìš°ë¡œ ìª¼ê°œê¸°)
def load_and_preprocess_data():
    X, y = [], []

    for file in os.listdir(DATA_FOLDER):
        if file.endswith(".csv"):
            df = pd.read_csv(os.path.join(DATA_FOLDER, file))
            if not set(COLS).issubset(df.columns): continue

            signals = df[COLS].values
            label = df['label'].values[0]

            for i in range(0, len(signals) - WINDOW_SIZE, STRIDE):
                window = signals[i:i + WINDOW_SIZE]
                X.append(window)
                y.append(label)

    X = np.array(X)
    y = LabelEncoder().fit_transform(y)
    print(f"âœ… ì´ ìƒ˜í”Œ ìˆ˜: {len(X)}, í´ë˜ìŠ¤: {set(y)}")
    return X, y


# --------------------------------------------


# --------------------------------------------
# 4. ëª¨ë¸ ì •ì˜ + í•™ìŠµ
def build_model(input_shape, num_classes):
    model = models.Sequential()
    model.add(layers.Conv1D(64, 5, activation='relu', input_shape=input_shape))
    model.add(layers.MaxPooling1D(2))
    model.add(layers.Conv1D(128, 3, activation='relu'))
    model.add(layers.GlobalAveragePooling1D())
    model.add(layers.Dense(64, activation='relu'))
    model.add(layers.Dense(num_classes, activation='softmax'))
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return model


def train_model(X, y):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
    model = build_model(X.shape[1:], num_classes=len(set(y)))
    model.fit(X_train, y_train, epochs=15, batch_size=32, validation_data=(X_test, y_test))
    model.save(MODEL_PATH)
    print(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {MODEL_PATH}")


# --------------------------------------------


# --------------------------------------------
# 5. ì‹¤ì‹œê°„ ì¶”ë¡ 
def predict_thought():
    print("ğŸ” EEG ìŠ¤íŠ¸ë¦¼ ì—°ê²° ì¤‘ (ì‹¤ì‹œê°„ ì¶”ë¡ )...")
    streams = resolve_byprop('type', 'EEG', timeout=10)
    inlet = StreamInlet(streams[0])

    model = tf.keras.models.load_model(MODEL_PATH)
    buffer = deque(maxlen=WINDOW_SIZE)

    print("ğŸ§  ì‹¤ì‹œê°„ ì¶”ë¡  ì‹œì‘! (ìƒê°í•´ë³´ì„¸ìš”...)")

    while True:
        sample, _ = inlet.pull_sample()
        buffer.append(sample)

        if len(buffer) == WINDOW_SIZE:
            X_input = np.expand_dims(np.array(buffer), axis=0)
            pred = model.predict(X_input, verbose=0)
            pred_label = np.argmax(pred)
            confidence = np.max(pred)
            print(f"ğŸ§  ì˜ˆì¸¡: {pred_label} | í™•ë¥ : {confidence:.2f}")
            time.sleep(0.5)


# --------------------------------------------


# --------------------------------------------
# ğŸ“Œ ì‹¤í–‰ íë¦„
if __name__ == "__main__":
    try:
        stream_proc = start_stream()

        # 1. ë°ì´í„° ìˆ˜ì§‘
        while True:
            label = input("ìˆ˜ì§‘í•  ë¼ë²¨ ì…ë ¥ (ì˜ˆ: a, rest), ë˜ëŠ” ì—”í„° ì‹œ ì¢…ë£Œ: ").strip()
            if not label:
                break
            collect_data(label)

        stop_stream(stream_proc)

        # 2. ì „ì²˜ë¦¬ + í•™ìŠµ
        print("\nğŸ“Š ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ ì¤‘...")
        X, y = load_and_preprocess_data()
        train_model(X, y)

        # 3. ì‹¤ì‹œê°„ ì¶”ë¡  ì‹œì‘
        input("\nâ–¶ï¸ [Enter] í‚¤ë¥¼ ëˆ„ë¥´ë©´ ì‹¤ì‹œê°„ ì¶”ë¡ ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        stream_proc = start_stream()
        predict_thought()

    except KeyboardInterrupt:
        stop_stream(stream_proc)
        print("\nğŸ›‘ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨.")
    except Exception as e:
        stop_stream(stream_proc)
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")